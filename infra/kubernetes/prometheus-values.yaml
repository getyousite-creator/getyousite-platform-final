# ============================================================================
# Prometheus Stack Helm Chart Values
# ============================================================================
# Complete monitoring solution with Prometheus, Grafana, Alertmanager
# Custom dashboards for error rate, latency P99, and resource usage
# ============================================================================

# values-prometheus.yaml

prometheus:
  enabled: true
  
  prometheusSpec:
    # Retention
    retention: 30d
    retentionSize: 100GB
    
    # Resources
    resources:
      requests:
        cpu: 500m
        memory: 2Gi
      limits:
        cpu: 2000m
        memory: 8Gi
    
    # Storage
    storageSpec:
      volumeClaimTemplate:
        spec:
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: 100Gi
          storageClassName: gp3
    
    # Service Monitor selector
    serviceMonitorSelector: {}
    podMonitorSelector: {}
    
    # Additional scrape configs
    additionalScrapeConfigs:
      - job_name: 'karpenter'
        static_configs:
          - targets: ['karpenter:8080']
      
      - job_name: 'nginx-ingress'
        static_configs:
          - targets: ['nginx-ingress-controller:10254']

alertmanager:
  enabled: true
  
  alertmanagerSpec:
    # Resources
    resources:
      requests:
        cpu: 100m
        memory: 128Mi
      limits:
        cpu: 200m
        memory: 256Mi
    
    # Storage
    storage:
      volumeClaimTemplate:
        spec:
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: 10Gi
    
    # Configuration
    config:
      global:
        resolve_timeout: 5m
        slack_api_url: 'https://hooks.slack.com/services/XXX/YYY/ZZZ'
      
      route:
        group_by: ['alertname', 'cluster', 'service']
        group_wait: 30s
        group_interval: 5m
        repeat_interval: 12h
        receiver: 'slack-notifications'
        routes:
          - match:
              severity: critical
            receiver: 'slack-critical'
          - match:
              severity: warning
            receiver: 'slack-warning'
      
      receivers:
        - name: 'slack-notifications'
          slack_configs:
            - channel: '#alerts'
              send_resolved: true
              title: '{{ template "slack.title" . }}'
              text: '{{ template "slack.text" . }}'
        
        - name: 'slack-critical'
          slack_configs:
            - channel: '#alerts-critical'
              send_resolved: true
              title: 'ðŸš¨ CRITICAL: {{ .GroupLabels.alertname }}'
              text: '{{ range .Alerts }}{{ .Annotations.description }}{{ end }}'
        
        - name: 'slack-warning'
          slack_configs:
            - channel: '#alerts-warning'
              send_resolved: true
              title: 'âš ï¸ WARNING: {{ .GroupLabels.alertname }}'
              text: '{{ range .Alerts }}{{ .Annotations.description }}{{ end }}'

grafana:
  enabled: true
  
  # Admin credentials
  adminPassword: "changeme-use-secrets"
  
  # Resources
  resources:
    requests:
      cpu: 100m
      memory: 256Mi
    limits:
      cpu: 500m
      memory: 1Gi
  
  # Storage
  persistence:
    enabled: true
    size: 20Gi
    storageClassName: gp3
  
  # Datasources
  datasources:
    datasources.yaml:
      apiVersion: 1
      datasources:
        - name: Prometheus
          type: prometheus
          url: http://prometheus-server:80
          access: proxy
          isDefault: true
        - name: Loki
          type: loki
          url: http://loki:3100
          access: proxy
  
  # Dashboard providers
  dashboardProviders:
    dashboardproviders.yaml:
      apiVersion: 1
      providers:
        - name: 'default'
          orgId: 1
          folder: ''
          type: file
          disableDeletion: false
          editable: true
          options:
            path: /var/lib/grafana/dashboards/default
  
  # Dashboards
  dashboards:
    default:
      kubernetes-cluster:
        gnetId: 6417
        revision: 1
        datasource: Prometheus
      kubernetes-pods:
        gnetId: 6336
        revision: 1
        datasource: Prometheus
      node-exporter:
        gnetId: 1860
        revision: 1
        datasource: Prometheus
      nginx-ingress:
        gnetId: 9614
        revision: 1
        datasource: Prometheus
  
  # Sidecar for dashboards
  sidecar:
    dashboards:
      enabled: true
      searchNamespace: ALL
    datasources:
      enabled: true

# ============================================================================
# CUSTOM ALERTING RULES
# ============================================================================

prometheusRules:
  enabled: true
  
  rules:
    groups:
      - name: getyousite-alerts
        interval: 30s
        rules:
          # Error Rate > 0.1%
          - alert: HighErrorRate
            expr: |
              sum(rate(http_requests_total{status=~"5.."}[5m])) 
              / sum(rate(http_requests_total[5m])) > 0.001
            for: 2m
            labels:
              severity: critical
            annotations:
              summary: "High error rate detected"
              description: "Error rate is {{ $value | humanizePercentage }} (threshold: 0.1%)"
          
          # Latency P99 > 1s
          - alert: HighLatencyP99
            expr: |
              histogram_quantile(0.99, sum(rate(http_request_duration_seconds_bucket[5m])) by (le)) > 1
            for: 5m
            labels:
              severity: warning
            annotations:
              summary: "High P99 latency detected"
              description: "P99 latency is {{ $value | humanizeDuration }} (threshold: 1s)"
          
          # Memory usage > 80%
          - alert: HighMemoryUsage
            expr: |
              (container_memory_usage_bytes / container_spec_memory_limit_bytes) * 100 > 80
            for: 5m
            labels:
              severity: warning
            annotations:
              summary: "High memory usage detected"
              description: "Memory usage is {{ $value | humanizePercentage }} (threshold: 80%)"
          
          # CPU usage > 90%
          - alert: HighCPUUsage
            expr: |
              (rate(container_cpu_usage_seconds_total[5m]) / container_spec_cpu_quota) * 100 > 90
            for: 5m
            labels:
              severity: warning
            annotations:
              summary: "High CPU usage detected"
              description: "CPU usage is {{ $value | humanizePercentage }} (threshold: 90%)"
          
          # Pod not ready
          - alert: PodNotReady
            expr: |
              kube_pod_status_ready{condition="true"} == 0
            for: 5m
            labels:
              severity: warning
            annotations:
              summary: "Pod not ready"
              description: "Pod {{ $labels.pod }} in namespace {{ $labels.namespace }} is not ready"
          
          # Node not ready
          - alert: NodeNotReady
            expr: |
              kube_node_status_condition{condition="Ready",status="true"} == 0
            for: 5m
            labels:
              severity: critical
            annotations:
              summary: "Node not ready"
              description: "Node {{ $labels.node }} is not ready"
          
          # PersistentVolume usage > 85%
          - alert: PersistentVolumeUsage
            expr: |
              (kubelet_volume_stats_used_bytes / kubelet_volume_stats_capacity_bytes) * 100 > 85
            for: 10m
            labels:
              severity: warning
            annotations:
              summary: "PersistentVolume usage high"
              description: "PV {{ $labels.persistentvolumeclaim }} usage is {{ $value | humanizePercentage }}"
          
          # Database connections > 90%
          - alert: DatabaseConnectionsHigh
            expr: |
              (pg_stat_activity_count / pg_settings_max_connections) * 100 > 90
            for: 5m
            labels:
              severity: warning
            annotations:
              summary: "Database connections high"
              description: "Database connections at {{ $value | humanizePercentage }}"
          
          # Backup failed
          - alert: BackupFailed
            expr: |
              increase(backup_failure_total[1h]) > 0
            for: 0m
            labels:
              severity: critical
            annotations:
              summary: "Backup failed"
              description: "Backup job failed in the last hour"
          
          # SSL certificate expiring soon
          - alert: SSLCertificateExpiringSoon
            expr: |
              probe_ssl_earliest_cert_expiry - time() < 86400 * 30
            for: 1h
            labels:
              severity: warning
            annotations:
              summary: "SSL certificate expiring soon"
              description: "SSL certificate expires in {{ $value | humanizeDuration }}"

# ============================================================================
# SERVICE MONITORS
# ============================================================================

serviceMonitor:
  enabled: true
  
  selector:
    matchLabels:
      app: getyousite
  
  namespaceSelector:
    matchNames:
      - production
  
  endpoints:
    - port: http
      interval: 30s
      scrapeTimeout: 10s
      path: /metrics

# ============================================================================
# POD MONITORS
# ============================================================================

podMonitor:
  enabled: true
  
  selector:
    matchLabels:
      app: getyousite
  
  namespaceSelector:
    matchNames:
      - production
  
  podMetricsEndpoints:
    - port: http
      interval: 30s
      path: /metrics
